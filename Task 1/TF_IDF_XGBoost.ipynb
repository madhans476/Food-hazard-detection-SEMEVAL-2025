{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLhsljO6sNmf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLcCndXNsNcP"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('TRAIN-DATASET-PATH')\n",
        "df.head(2).T\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIoTU6qXg6zL"
      },
      "source": [
        "## Class Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9IcnhHBSym-O"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df['hazard_category'] = label_encoder.fit_transform(df['hazard-category'])\n",
        "\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "\n",
        "label_mapping.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dkyVcXEJynsC"
      },
      "outputs": [],
      "source": [
        "df['product_category'] = label_encoder.fit_transform(df['product-category'])\n",
        "\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "\n",
        "label_mapping.items()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4A2UK2I2sNXO"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYUipVOAsNS_"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(sublinear_tf=True, max_df=0.75, max_features=3500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Xr39H39sNPa"
      },
      "outputs": [],
      "source": [
        "features = tfidf.fit_transform(df['text'].astype(str)).toarray()\n",
        "df['vector'] = list(features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2MJxWVBhOwR"
      },
      "source": [
        "## Hazard Category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUCqH3CasNEe"
      },
      "outputs": [],
      "source": [
        "X = df['vector']\n",
        "\n",
        "y = df['hazard_category']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZarFvSQsNBF"
      },
      "outputs": [],
      "source": [
        "# X = X.apply(lambda x: np.fromstring(x.strip('[]'), sep=' '))\n",
        "import numpy as np\n",
        "X = np.stack(X.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHxeAyRxLuK6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.tolist(), y, test_size=0.1, random_state=42)\n",
        "type(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXlrv2_5zD-Z"
      },
      "outputs": [],
      "source": [
        "ct = y_train.value_counts().reset_index()\n",
        "print(ct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jJT-787sM92"
      },
      "outputs": [],
      "source": [
        "\n",
        "minority_classes = [6]\n",
        "\n",
        "X_majority = np.array(X_train)[~y_train.isin(minority_classes)]\n",
        "y_majority = y_train[~y_train.isin(minority_classes)]\n",
        "X_minority = np.array(X_train)[y_train.isin(minority_classes)]\n",
        "y_minority = y_train[y_train.isin(minority_classes)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzWtuChULuOa"
      },
      "outputs": [],
      "source": [
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(sampling_strategy='auto', k_neighbors=7, random_state=42)\n",
        "X_resampled_majority, y_resampled_majority = sm.fit_resample(X_majority, y_majority)\n",
        "\n",
        "X_combined = np.vstack((X_resampled_majority, X_minority))\n",
        "y_combined = np.concatenate((y_resampled_majority, y_minority))\n",
        "\n",
        "sm_minority = SMOTE(sampling_strategy='auto', k_neighbors=1, random_state=42)\n",
        "X_final_resampled, y_final_resampled = sm_minority.fit_resample(X_combined, y_combined)\n",
        "\n",
        "shuffled_indices = np.random.permutation(len(X_final_resampled))\n",
        "\n",
        "# Shuffle both Xs and ys using the same shuffled indices\n",
        "Xs_shuffled = X_final_resampled[shuffled_indices]\n",
        "ys_shuffled = y_final_resampled[shuffled_indices]\n",
        "\n",
        "Xs = Xs_shuffled\n",
        "ys = ys_shuffled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3mzDK-OLuH3"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(Xs)\n",
        "X_test = np.array(X_test)\n",
        "y_train = ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7YOt-syL7Ap"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D9gd4Q6Lt-Z"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "classifier = XGBClassifier(verbosity = 2)\n",
        "classifier.fit(X_train, y_train)\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36jMRzFtSkw5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzfQZa8ltF-2"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciYRkbReLt7j"
      },
      "outputs": [],
      "source": [
        "val_df = pd.read_csv(\"TEST-DATASET-PATH\")\n",
        "val_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7uZpZbiLt1p"
      },
      "outputs": [],
      "source": [
        "val_features = tfidf.transform(val_df[\"text\"]).toarray()\n",
        "val_df['vector'] = list(val_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQwH8QF7LtyR"
      },
      "outputs": [],
      "source": [
        "vx = np.stack(val_df['vector'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7U7NnhPLtr_"
      },
      "outputs": [],
      "source": [
        "class_names = [\"allergens\",\"biological\",\"chemical\",\"food additives and flavourings\",\"foreign bodies\",\"fraud\",\"migration\",\"organoleptic aspects\",\"other hazard\",\"packaging defect\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge1mXjH8cK_f"
      },
      "outputs": [],
      "source": [
        "xgboost_pred = classifier.predict(vx)\n",
        "predicted_class_names = [class_names[i] for i in xgboost_pred]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucxc5h-jcjTd"
      },
      "outputs": [],
      "source": [
        "predicted_class_df = pd.DataFrame(predicted_class_names, columns=['hazard-category-xgboost'])\n",
        "\n",
        "# Print the DataFrame to verify\n",
        "print(predicted_class_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_df.to_csv(\"submission_xg.csv\", index=False)"
      ],
      "metadata": {
        "id": "JLFIySWotaex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(val_df['hazard-category'], predicted_class_df['hazard-category-xgboost']))"
      ],
      "metadata": {
        "id": "vR4EUKp1uFCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aRbGOC8h1uO"
      },
      "source": [
        "## Product Category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjIQwfqbORjO"
      },
      "outputs": [],
      "source": [
        "X_p = df['vector']\n",
        "\n",
        "y_p = df['product_category']\n",
        "X_p = np.stack(X_p.values)\n",
        "\n",
        "ct = y_p.value_counts().reset_index()\n",
        "print(ct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLFIVX290TFC"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_p_train, X_p_test, y_p_train, y_p_test = train_test_split(X_p.tolist(), y_p, test_size=0.2, random_state=42)\n",
        "type(X_p_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ3_GDPk0mk4"
      },
      "outputs": [],
      "source": [
        "ct = y_p_train.value_counts().reset_index()\n",
        "print(ct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnuyNDV2ORf6"
      },
      "outputs": [],
      "source": [
        "\n",
        "minority_classes = [21,6,8,11,7]\n",
        "\n",
        "X_p_majority = np.array(X_p_train)[~y_p_train.isin(minority_classes)]\n",
        "y_p_majority = y_p_train[~y_p_train.isin(minority_classes)]\n",
        "X_p_minority = np.array(X_p_train)[y_p_train.isin(minority_classes)]\n",
        "y_p_minority = y_p_train[y_p_train.isin(minority_classes)]\n",
        "\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(sampling_strategy='auto', k_neighbors=7, random_state=42)\n",
        "X_p_resampled_majority, y_resampled_majority = sm.fit_resample(X_p_majority, y_p_majority)\n",
        "\n",
        "X_p_combined = np.vstack((X_p_resampled_majority, X_p_minority))\n",
        "y_p_combined = np.concatenate((y_resampled_majority, y_p_minority))\n",
        "\n",
        "sm_minority = SMOTE(sampling_strategy='auto', k_neighbors=3, random_state=42)\n",
        "X_p_final_resampled, y_p_final_resampled = sm_minority.fit_resample(X_p_combined, y_p_combined)\n",
        "\n",
        "shuffled_indices = np.random.permutation(len(X_p_final_resampled))\n",
        "\n",
        "# Shuffle both X_ps and y_ps using the same shuffled indices\n",
        "X_ps_shuffled = X_p_final_resampled[shuffled_indices]\n",
        "y_ps_shuffled = y_p_final_resampled[shuffled_indices]\n",
        "\n",
        "X_ps = X_ps_shuffled\n",
        "y_ps = y_ps_shuffled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz7ZpJ3Y0UKX"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_p_train = np.array(X_ps)\n",
        "X_p_test = np.array(X_p_test)\n",
        "y_p_train = y_ps\n",
        "X_p_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSucGZwSfPyA"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "classifier2 = XGBClassifier()\n",
        "classifier2.fit(X_p_train, y_p_train)\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "y_p_pred = classifier2.predict(X_p_test)\n",
        "cm = confusion_matrix(y_p_test, y_p_pred)\n",
        "print(cm)\n",
        "\n",
        "print(classification_report(y_p_test, y_p_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc0tNgUWtlbv"
      },
      "outputs": [],
      "source": [
        "\n",
        "class_names = [\"alcoholic beverages\",\n",
        "\"cereals and bakery products\",\n",
        "\"cocoa and cocoa preparations, coffee and tea\",\n",
        "\"confectionery\",\n",
        "\"dietetic foods, food supplements, fortified foods\",\n",
        "\"fats and oils\",\n",
        "\"feed materials\",\n",
        "\"food additives and flavourings\",\n",
        "\"food contact materials\",\n",
        "\"fruits and vegetables\",\n",
        "\"herbs and spices\",\n",
        "\"honey and royal jelly\",\n",
        "\"ices and desserts\",\n",
        "\"meat, egg and dairy products\",\n",
        "\"non-alcoholic beverages\",\n",
        "\"nuts, nut products and seeds\",\n",
        "\"other food product / mixed\",\n",
        "\"pet feed\",\n",
        "\"prepared dishes and snacks\",\n",
        "\"seafood\",\n",
        "\"soups, broths, sauces and condiments\",\n",
        "\"sugars and syrups\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vnxksOEyuRAQ"
      },
      "outputs": [],
      "source": [
        "xgboost_pred2 = classifier2.predict(vx)\n",
        "predicted_class_names = [class_names[i] for i in xgboost_pred2]\n",
        "predicted_class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0wDrZLQu354"
      },
      "outputs": [],
      "source": [
        "predicted_class_df['product-category'] = predicted_class_names\n",
        "predicted_class_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qu-gDEQstrFA"
      },
      "outputs": [],
      "source": [
        "\n",
        "predicted_class_df.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zg65CosCuQcg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tIoTU6qXg6zL"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}